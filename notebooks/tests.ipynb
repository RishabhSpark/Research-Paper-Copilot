{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac49fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bf9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = '../public/sample_papers/A_brief_history_of_Pfizer_Central_Research.pdf'\n",
    "doc = pymupdf.open(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0219c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_text_from_pdf(doc_path):\n",
    "#     doc = pymupdf.open(doc_path)\n",
    "#     complete_text = ''\n",
    "#     for page in doc: # iterate the document pages\n",
    "#         text = page.get_text() # get text of page\n",
    "#         complete_text += text # write text of page\n",
    "#     # out.close()\n",
    "#     return complete_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f754fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_text = extract_text_from_pdf(doc_path)\n",
    "# doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91433060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# # Load your environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# def get_summarizer_chain():\n",
    "#     api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "#     if not api_key:\n",
    "#         raise ValueError(\"Missing GOOGLE_API_KEY in s.env\")\n",
    "\n",
    "#     # Initialize the Gemini model\n",
    "#     llm = ChatGoogleGenerativeAI(\n",
    "#         model=\"gemini-1.5-flash\",\n",
    "#         temperature=0.4,\n",
    "#         google_api_key=api_key\n",
    "#     )\n",
    "\n",
    "#     # Define prompt template\n",
    "#     prompt = PromptTemplate(\n",
    "#         input_variables=[\"text\"],\n",
    "#         template=\"Summarize the following research paper content:\\n\\n{text}\\n\\nSummary:\"\n",
    "#     )\n",
    "\n",
    "#     # Create LangChain LLMChain\n",
    "#     chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "#     return chain\n",
    "\n",
    "# def summarize_text(text: str) -> str:\n",
    "#     chain = get_summarizer_chain()\n",
    "#     result = chain.run({\"text\": text})\n",
    "#     return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e16fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_text = doc_text\n",
    "# summary = summarize_text(long_text)\n",
    "# print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2055036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PDF LOADER] Loaded 76 page(s) from 'C:\\Users\\khand\\OneDrive\\Desktop\\Rishabh\\Agentic AI\\Research Paper Copilot\\Research-Paper-Copilot\\public\\sample_papers\\A_brief_history_of_Pfizer_Central_Research.pdf'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "import sys\n",
    "\n",
    "filepath = \"C:\\\\Users\\\\khand\\\\OneDrive\\\\Desktop\\\\Rishabh\\\\Agentic AI\\\\Research Paper Copilot\\\\Research-Paper-Copilot\\\\public\\\\sample_papers\\\\A_brief_history_of_Pfizer_Central_Research.pdf\"\n",
    "loader = PyMuPDFLoader(filepath)\n",
    "documents = loader.load()\n",
    "print(f\"[PDF LOADER] Loaded {len(documents)} page(s) from '{filepath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17787f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CHUNKER] split documents into 732 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 500\n",
    "chunk_overlap = 100\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "chunked_docs = splitter.split_documents(documents)\n",
    "print(f'[CHUNKER] split documents into {len(chunked_docs)} chunks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daee5460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "ling.\n",
      "Sterling Drug, Inc.\n",
      "Edward S. Hills, a semi-retired lawyer whose firm had\n",
      "represented Sterling in trade mark negotiations, was\n",
      "named the new chairman of Sterling; but the effective\n",
      "operating officer was the former treasurer, James Hill,\n",
      "Jr., who kept Sterling on course.  Because of possible\n",
      "confusion with other companiesâ€™ names, Sterling Prod-\n",
      "ucts could not be licensed to carry on business in cer-\n",
      "tain states and so on October 15, 1942 the company name\n",
      "235\n",
      "tain states and so on October 15, 1942 the company name\n",
      "was changed to Sterling Drug, Inc.  A major acquisition\n",
      "in 1942 was the Salvo Chemical Corporation.  It had\n",
      "been founded in 1930 to convert lignin from lumber\n",
      "wastes into vanillin.  Sterling already sold this compound\n",
      "for flavorings through its General Drug division; but be-\n",
      "cause the big tonnages were used in rubber for tires,\n",
      "Sterling was now in the critical war materials business.\n",
      "Effluent treatment was a problem until Salvo found that\n"
     ]
    }
   ],
   "source": [
    "for i in range(234, 236):\n",
    "    print(i)\n",
    "    print(chunked_docs[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = []\n",
    "    \n",
    "for doc in documents:\n",
    "    embedding = model.encode(doc.page_content)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "print(f'Generated embeddings for {len(documents)} chunks.')\n",
    "\n",
    "    return embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-paper-copilot-xnqBW2pO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
